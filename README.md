# CritiqueBench - RAG Evaluation Framework

CritiqueBench is an automated framework for evaluating Retrieval-Augmented Generation (RAG) systems. It implements multiple RAG strategies and provides comprehensive evaluation metrics including LLM-as-judge scores and traditional NLP metrics.

## Features

- **Multiple RAG Strategies**:
  - Simple retrieval
  - Multi-query retrieval
  - Hypothetical Document Embeddings (HyDE)
  
- **Comprehensive Evaluation**:
  - Faithfulness (hallucination detection)
  - Answer relevance
  - Context relevance
  - Traditional metrics (BLEU, ROUGE)
  
- **Interactive Dashboard**:
  - Streamlit-based UI
  - Visual comparison of metrics
  - Context inspection

## Installation

1. Clone the repository: